import time
import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error as MAE

from UCTB.dataset import NodeTrafficLoader
from UCTB.preprocess import SplitData, Normalizer
from UCTB.evaluation import metric
from UCTB.model import STORM
from UCTB.preprocess.GraphGenerator import GraphGenerator

class storm_data_loader(NodeTrafficLoader):
    def __init__(self, **kwargs):
        """A wrapper of ``NodeTrafficLoader`` to make its data form compatible with STORM's inputs. Setting the data range is currently not supported. If you need to modify the data range, you can regenerate a dataset.

        Args:
            **kwargs (dict): Used to pass other parameters to class ``NodeTrafficLoader``.

        Attributes:
            - dataset.data['Node']['POI'] (list): A list, where each element represents the statistical quantity of various POI types near the corresponding station area.
            - train_tef_closeness (np.ndarray): The closeness history shape of tran temporal external feature. Its shape is [train_time_slot_num, temproal_external_dim, closeness_len, 1], train_tef_periof, train_tef_trend, test_closeness, test_period, test_trend have similar shape and construction.
            - train_sef (np.ndarray): The train spatial external feature. Its shape is [train_sequence_len, station_number], test_sef have similar shape and construction.
        """
        super(storm_data_loader, self).__init__(**kwargs)
        num_time_slots = len(self.traffic_data)
        # build multi-graph need station location, traffic, poi. If POI data is missing, an all-zero POI data of shape [station_num, 2] is generated by default.
        if not 'POI' in self.dataset.data['Node']:
            self.dataset.data['Node']['POI'] = np.array([])
        if len(self.dataset.data['Node']['POI']) == 0:
            self.dataset.data['Node']['POI'] = np.zeros((self.station_number, 2))
        # build multi-task requires a time-series feature that corresponds one-to-one with the time of traffic flow. If missing, weather and time features are used instead.
        if not 'TemporalExternalFeature' in self.dataset.data['ExternalFeature']:
            tef = []
            if 'Weather' in self.dataset.data['ExternalFeature'] and len(self.dataset.data['ExternalFeature']['Weather']) > 0:
                tef.append(self.dataset.data['ExternalFeature']['Weather'][0:num_time_slots, :])
            if 'Time' in self.dataset.data['ExternalFeature'] and len(self.dataset.data['ExternalFeature']['Time']) > 0:
                tef.append(self.dataset.data['ExternalFeature']['Time'][0:num_time_slots, :])
        else:
            tef = self.dataset.data['ExternalFeature']['TemporalExternalFeature']
        if len(tef) > 0:
            tef = np.concatenate(tef, axis=-1).astype(np.float32)
            self.tef_dim = tef.shape[1]
            normalize_tef = True
        else:
            tef = np.zeros((len(self.dataset.node_traffic), 2))
            self.tef_dim = 0
            normalize_tef = False

        # build multi-view requires a feature that has the same shape as the station traffic matrix. It is used to express the impact on the traffic of different stations at different times. If missing, all zeros are used.
        if not 'SpatialExternalFeature' in self.dataset.data['ExternalFeature']:
            sef = np.zeros(self.traffic_data.shape)
            normalize_sef = False
        else:
            sef = self.dataset.data['ExternalFeature']['SpatialExternalFeature']
            normalize_sef = True

        # preprocess
        self.train_tef, self.test_tef = SplitData.split_data(tef, self.train_test_ratio)
        self.train_sef, self.test_sef = SplitData.split_data(sef, self.train_test_ratio)
        # Normalize
        if normalize_sef:
            self.normalizer_sef = Normalizer(self.train_sef)
            self.train_sef = self.normalizer_sef.min_max_normal(self.train_sef)
            self.test_sef = self.normalizer_sef.min_max_normal(self.test_sef)
        if normalize_tef:
            self.normalizer_tef = Normalizer(self.train_tef)
            self.train_tef = self.normalizer_tef.min_max_normal(self.train_tef)
            self.test_tef = self.normalizer_tef.min_max_normal(self.test_tef)

        # expand the test data
        expand_start_index = len(self.train_data) - max(int(self.daily_slots * self.period_len), int(self.daily_slots * 7 * self.trend_len), self.closeness_len)
        self.test_tef = np.vstack([self.train_tef[expand_start_index:], self.test_tef])
        self.test_sef = np.vstack([self.train_sef[expand_start_index:], self.test_sef])
        # temporal external feature, train_tef_closeness shape is [len(test_data)-max_input_window, temproal_external_dim, closeness_len, 1]
        self.train_tef_closeness, \
        self.train_tef_period, \
        self.train_tef_trend, \
        self.train_tef_y = self.st_move_sample.move_sample(self.train_tef)
        self.test_tef_closeness, \
        self.test_tef_period, \
        self.test_tef_trend, \
        self.test_tef_y = self.st_move_sample.move_sample(self.test_tef)

        # spatial external feature, train_sef shape is [train_sequence_len, station_number], test_sef shape is [test_sequence_len, station_number]
        self.train_sef = self.train_sef[-self.train_sequence_len - kwargs['target_length']: -kwargs['target_length']]
        self.test_sef = self.test_sef[-self.test_sequence_len - kwargs['target_length']: -kwargs['target_length']]



# params
dataset_name = "hospital_hour"
# dataset_name = "Bike_NYC"
model_name = 'STORM'
gpu_device = '0'
output_path = "./"+dataset_name
code_version = model_name+"-"+dataset_name
n_pred = 6
gcn_k = 1
gcn_layers = 1
gclstm_layers = 2
gru_layers = 1

# data_loader
data_loader = storm_data_loader(dataset=dataset_name.split('_')[0], city=dataset_name.split('_')[1], closeness_len=6, period_len=7, trend_len=0, target_length=n_pred, test_ratio=0.2)

# Build Graph
graph_obj = GraphGenerator(graph='Correlation-Function-Distance', data_loader=data_loader)

start = time.time()

# define n_pred model to train
model_list = []
temp_predict = []
temp_traffic_predict = []
temp_tef_predict = []
temp_closeness_feature = data_loader.train_closeness
temp_tef_feature = data_loader.train_tef_closeness
for i in range(n_pred):
    temp_closeness_len = data_loader.closeness_len + i
    temp_code_version = code_version + "-Step_"+ str(i+1)
    if i != 0:
        temp_closeness_feature = np.concatenate((temp_closeness_feature,temp_traffic_predict), axis=2)
        temp_tef_feature = np.concatenate((temp_tef_feature,temp_tef_predict), axis=2)
    temp_model = STORM(num_node=data_loader.station_number,
            external_dim = data_loader.tef_dim,
            closeness_len=temp_closeness_len,
            period_len=data_loader.period_len, 
            trend_len=0,
            num_graph = graph_obj.LM.shape[0],
            gcn_k=gcn_k,
            gcn_layers = gcn_layers,
            gclstm_layers= gclstm_layers,
            gru_layers = gcn_layers,
            num_hidden_units=64,
            num_dense_units=32,
            lr = 5e-4,
            loss_w_node = 1.0,
            loss_w_tef = 1.0,
            code_version=temp_code_version,
            gpu_device=gpu_device)
    # tf-graph
    temp_model.build()
    # training
    temp_model.fit(laplace_matrix=graph_obj.LM,
            closeness_traffic_feature=temp_closeness_feature,
            period_traffic_feature=data_loader.train_period,
            target_traffic=data_loader.train_y[:,:,i].reshape((-1, data_loader.station_number, 1)),
            closeness_external_feature=temp_tef_feature,
            period_external_feature = data_loader.train_tef_period,
            target_external = data_loader.train_tef_y[:,:,i].reshape((-1, data_loader.tef_dim, 1)),
            spatial_external_feature = data_loader.train_sef,
            sequence_length=data_loader.train_sequence_len,
            output_names=['loss', 'prediction', 'external_prediction'],
            max_epoch=100,
            auto_load_model = False)
    # save
    model_list.append(temp_model)
    # prediction
    temp_predict = temp_model.predict(
        laplace_matrix=graph_obj.LM,
        closeness_traffic_feature=temp_closeness_feature,
        period_traffic_feature=data_loader.train_period,
        target_traffic=data_loader.train_y[:,:,i].reshape((-1, data_loader.station_number, 1)),
        closeness_external_feature=temp_tef_feature,
        period_external_feature = data_loader.train_tef_period,
        target_external = data_loader.train_tef_y[:,:,i].reshape((-1, data_loader.tef_dim, 1)),
        spatial_external_feature = data_loader.train_sef,
        output_names=['prediction', 'external_prediction'],
        sequence_length=data_loader.train_sequence_len
    )
    temp_traffic_predict = temp_predict['prediction']
    temp_traffic_predict = temp_traffic_predict.reshape((temp_traffic_predict.shape[0], temp_traffic_predict.shape[1], 1, 1))
    temp_tef_predict = temp_predict['external_prediction']
    temp_tef_predict = temp_tef_predict.reshape((temp_tef_predict.shape[0], temp_tef_predict.shape[1], 1, 1))

# use n_pred model to predict n_pred step
predict_list = []
temp_traffic_predict = []
temp_tef_predict = []
temp_closeness_feature = data_loader.test_closeness
temp_tef_feature = data_loader.test_tef_closeness
for i in range(n_pred):
    temp_model = model_list[i]
    if i != 0:
        temp_closeness_feature = np.concatenate((temp_closeness_feature,temp_traffic_predict), axis=2)
        temp_tef_feature = np.concatenate((temp_tef_feature,temp_tef_predict), axis=2)
    temp_predict = temp_model.predict(
        laplace_matrix=graph_obj.LM,
        closeness_traffic_feature=temp_closeness_feature,
        period_traffic_feature=data_loader.test_period,
        target_traffic=data_loader.test_y[:,:,i].reshape((-1, data_loader.station_number, 1)),
        closeness_external_feature=temp_tef_feature,
        period_external_feature = data_loader.test_tef_period,
        target_external = data_loader.test_tef_y[:,:,i].reshape((-1, data_loader.tef_dim, 1)),
        spatial_external_feature = data_loader.test_sef,
        output_names=['prediction', 'external_prediction'],
        sequence_length=data_loader.test_sequence_len
    )
    temp_traffic_predict = temp_predict['prediction']
    predict_list.append(temp_traffic_predict)
    temp_traffic_predict = temp_traffic_predict.reshape((temp_traffic_predict.shape[0], temp_traffic_predict.shape[1], 1, 1))
    temp_tef_predict = temp_predict['external_prediction']
    temp_tef_predict = temp_tef_predict.reshape((temp_tef_predict.shape[0], temp_tef_predict.shape[1], 1, 1))

print('Total time cost is %.3f' % float(time.time()-start))
# Evaluation
predict_list = np.concatenate(predict_list, axis=2)
prediction = data_loader.normalizer.min_max_denormal(predict_list)
prediction = np.where(prediction>0, prediction, 0)
target = data_loader.normalizer.min_max_denormal(data_loader.test_y)

evaluation_result = pd.DataFrame(columns=["MAE", "RMSE", "MAPE"], index=range(1, n_pred+1))
for i in range(n_pred):
    # reshape
    cur_prediction = prediction[:,:,i]
    cur_target = target[:,:,i]
    # result
    mae = MAE(cur_prediction, cur_target)
    rmse = metric.rmse(cur_prediction, cur_target, threshold=0)
    mape = metric.mape(cur_prediction, cur_target, threshold=0.1)
    # save
    evaluation_result.loc[i+1, "MAE"] = mae
    evaluation_result.loc[i+1, "RMSE"] = rmse
    evaluation_result.loc[i+1, "MAPE"] = mape
    # print
    print("Step %02d, MAE: %.4f, RMSE: %.4f, MAPE:%.4f" % (i+1, mae, rmse, mape))

# save
np.save(output_path + '-prediction.npy', prediction)
np.save(output_path + '-target.npy', target)
evaluation_result.to_csv(output_path + '-evaluation.csv', float_format="%.4f")